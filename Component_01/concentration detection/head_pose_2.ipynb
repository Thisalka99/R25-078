{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "623ce6ec-c885-47d6-b981-516afecf4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3343a156-5c6a-4cdc-b74e-e25c26db44d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MediaPipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "# Indices for iris landmarks and eye corners\n",
    "left_iris_indices = [474, 475, 476, 477]\n",
    "right_iris_indices = [469, 470, 471, 472]\n",
    "left_eye_inner = 362\n",
    "left_eye_outer = 263\n",
    "right_eye_inner = 133\n",
    "right_eye_outer = 33\n",
    "\n",
    "# Function to calculate iris position\n",
    "def get_iris_position(face_landmarks, iris_indices, frame_width, frame_height):\n",
    "    iris_x = np.mean([face_landmarks.landmark[i].x for i in iris_indices]) * frame_width\n",
    "    iris_y = np.mean([face_landmarks.landmark[i].y for i in iris_indices]) * frame_height\n",
    "    return (iris_x, iris_y)\n",
    "\n",
    "# Function to calculate the relative position of the iris within the eye\n",
    "def calculate_relative_position(iris_pos, eye_inner_pos, eye_outer_pos):\n",
    "    eye_width = eye_outer_pos[0] - eye_inner_pos[0]\n",
    "    iris_offset_x = iris_pos[0] - eye_inner_pos[0]\n",
    "    iris_relative_x = iris_offset_x / eye_width  # 0.5 means looking straight\n",
    "    return iris_relative_x\n",
    "\n",
    "# Head pose estimation\n",
    "def get_head_pose(face_landmarks, frame_width, frame_height, camera_matrix, dist_coeffs):\n",
    "    model_points = np.array([\n",
    "        (0.0, 0.0, 0.0),  # Nose tip\n",
    "        (0.0, -330.0, -65.0),  # Chin\n",
    "        (-225.0, 170.0, -135.0),  # Left eye corner\n",
    "        (225.0, 170.0, -135.0),  # Right eye corner\n",
    "        (-150.0, -150.0, -125.0),  # Left mouth corner\n",
    "        (150.0, -150.0, -125.0)  # Right mouth corner\n",
    "    ])\n",
    "\n",
    "    image_points = np.array([\n",
    "        (face_landmarks.landmark[1].x * frame_width, face_landmarks.landmark[1].y * frame_height),  # Nose tip\n",
    "        (face_landmarks.landmark[152].x * frame_width, face_landmarks.landmark[152].y * frame_height),  # Chin\n",
    "        (face_landmarks.landmark[33].x * frame_width, face_landmarks.landmark[33].y * frame_height),  # Left eye corner\n",
    "        (face_landmarks.landmark[263].x * frame_width, face_landmarks.landmark[263].y * frame_height),  # Right eye corner\n",
    "        (face_landmarks.landmark[61].x * frame_width, face_landmarks.landmark[61].y * frame_height),  # Left mouth corner\n",
    "        (face_landmarks.landmark[291].x * frame_width, face_landmarks.landmark[291].y * frame_height)  # Right mouth corner\n",
    "    ], dtype='float64')\n",
    "\n",
    "    success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "        model_points, image_points, camera_matrix, dist_coeffs)\n",
    "    \n",
    "    # Get rotation matrix and euler angles\n",
    "    rvec_matrix = cv2.Rodrigues(rotation_vector)[0]\n",
    "    proj_matrix = np.hstack((rvec_matrix, translation_vector))\n",
    "    eulerAngles = cv2.decomposeProjectionMatrix(proj_matrix)[6]\n",
    "    pitch, yaw, roll = eulerAngles  # Extract head orientation angles\n",
    "    \n",
    "    return pitch, yaw, roll\n",
    "\n",
    "# Camera internals\n",
    "frame_width = 640\n",
    "frame_height = 480\n",
    "focal_length = frame_width\n",
    "center = (frame_width / 2, frame_height / 2)\n",
    "camera_matrix = np.array([[focal_length, 0, center[0]],\n",
    "                          [0, focal_length, center[1]],\n",
    "                          [0, 0, 1]], dtype='float64')\n",
    "dist_coeffs = np.zeros((4, 1))  # assuming no distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c598aefa-92af-4fbc-9e92-18c4b4ac7c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "\n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Empty camera frame.\")\n",
    "            continue\n",
    "\n",
    "        # Get frame dimensions\n",
    "        frame_height, frame_width, _ = image.shape\n",
    "\n",
    "        # Process the image for face landmarks\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image)\n",
    "\n",
    "        # Convert the image back to BGR for OpenCV\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            for face_landmarks in results.multi_face_landmarks:\n",
    "                # Extract iris positions\n",
    "                left_iris_pos = get_iris_position(face_landmarks, left_iris_indices, frame_width, frame_height)\n",
    "                right_iris_pos = get_iris_position(face_landmarks, right_iris_indices, frame_width, frame_height)\n",
    "\n",
    "                # Extract eye corner positions\n",
    "                left_eye_inner_pos = (face_landmarks.landmark[left_eye_inner].x * frame_width,\n",
    "                                      face_landmarks.landmark[left_eye_inner].y * frame_height)\n",
    "                left_eye_outer_pos = (face_landmarks.landmark[left_eye_outer].x * frame_width,\n",
    "                                      face_landmarks.landmark[left_eye_outer].y * frame_height)\n",
    "                right_eye_inner_pos = (face_landmarks.landmark[right_eye_inner].x * frame_width,\n",
    "                                       face_landmarks.landmark[right_eye_inner].y * frame_height)\n",
    "                right_eye_outer_pos = (face_landmarks.landmark[right_eye_outer].x * frame_width,\n",
    "                                       face_landmarks.landmark[right_eye_outer].y * frame_height)\n",
    "\n",
    "                # Calculate relative iris positions for both eyes\n",
    "                left_iris_relative_x = calculate_relative_position(left_iris_pos, left_eye_inner_pos, left_eye_outer_pos)\n",
    "                right_iris_relative_x = calculate_relative_position(right_iris_pos, right_eye_inner_pos, right_eye_outer_pos)\n",
    "\n",
    "                # Head pose estimation (pitch, yaw, roll)\n",
    "                pitch, yaw, roll = get_head_pose(face_landmarks, frame_width, frame_height, camera_matrix, dist_coeffs)\n",
    "\n",
    "                # Adjust the gaze detection based on head pose\n",
    "                # If head is turned slightly\n",
    "                horizontal_adjustment = 0.1 * abs(yaw / 70)  # Adjust the threshold based on head yaw\n",
    "                if (0.4 - horizontal_adjustment/2) < left_iris_relative_x < (0.6 + horizontal_adjustment/2) and \\\n",
    "                   (0.4 - horizontal_adjustment) < right_iris_relative_x < (0.6 + horizontal_adjustment):\n",
    "                    gaze_text = \"Concentrated\"\n",
    "                    color = (0, 255, 0)\n",
    "                else:\n",
    "                    gaze_text = \"Not Concentrated\"\n",
    "                    color = (0, 0, 255)\n",
    "\n",
    "                # Display gaze direction on the screen\n",
    "                # cv2.putText(image, gaze_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "            cv2.putText(image, gaze_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        # Show the image with gaze and head pose estimation\n",
    "        cv2.imshow('Eyeball & Head Pose Detection', image)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
